---
title: "Movie Recommendation Model - edx"
author: "Suliman Alkhalifa"
date: "12 April 2019"
output:
  html_document: default
  pdf_document: default
---

## Project Overview

For this project, the objective is to build a recommendation system for users to watch movies. I am happy to be working in such a project as I like watching movies and have always been wondering how the system knows what I like and don't like. Now, it is an opportunity to build a similar system and learn from my peers. After searching for best practices on how to build an accurate model/system for recommending movies, I decided for this project to use three different models which I learned from previous courses and then compare the results to see which one is the best.

## Used Libraries

I will use the following libraries for my project:

```{r libs, echo=TRUE}
library(tidyverse)
library(caret)
library(ggplot2)
```

## Data Gathering

The dataset used was from Movielens as suggested in the course and I used the same codes provided to download the data.

```{r data_load, echo=TRUE}
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
```

## Data Pre-processing

I will use the ratings and movies files from the list of files downloaded.

```{r data_process, echo=TRUE}
ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
```

I will add column names to movies data and change their classes as follow:

```{r data_process_2, echo=TRUE}
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))
```

Next is to join the ratings and movies datasets into movielens dataset:

```{r data_process_3, echo=TRUE}
movielens <- left_join(ratings, movies, by = "movieId")
```

## Data Exploration

Let us take a look at some of the dataset features and insights

First is to view how many rows and columns:

```{r row_col_count, echo=TRUE}
nrow(movielens)
ncol(movielens)
```

Second is to look at summary of the movies and ratings:

```{r mov_rat_summ, echo=TRUE}
summary(movielens)
```

Next is to see how many unique movies, ratings and users we have:

```{r unique_movies_users, echo=TRUE}
movielens %>% 
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId),
            n_ratings = n_distinct(rating))
```

The number of users exceeds the number of movies which indicates that users may have rated more than one movie at different times.

Next is to see the distribution of ratings:

```{r rat_dist, echo=TRUE}
hist(movielens$rating, col = "grey", main = "Distribution of ratings",
     xlab = "ratings", ylab = "count", xlim = range(0.5,5))
```

We can see that majority of ratings start from 3 and above and the most common rating is 4. Also, half star ratings are less common than full star ratings.

In addition, we can look at the distribution of movies:

```{r movie_dist, echo=TRUE}
movielens %>% count(movieId) %>% ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "grey") + scale_x_log10() + 
  ggtitle("Distribution of Movies")
```

This shows that some movies are rated many times as they are popular and many users have rated them.

We will also look at the distribution of users:

```{r user_dist, echo=TRUE}
movielens %>% count(userId) %>% ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "grey") + scale_x_log10() + 
  ggtitle("Distribution of Users")
```

This indicates that some users are more active than others.

The next code is to show a list of top movies rated:

```{r top_movies, echo=TRUE}
movielens %>% group_by(movieId, title) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
```

## Data Preparation

First I will create the training and testing set. I will use 10% of the dataset for the testing and 90% for the training set.

```{r test_set, echo=TRUE}
set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
train_set <- movielens[-test_index,]
temp <- movielens[test_index,]
```

Make sure the userId and movieId in the testing set are also in the training set.

```{r test_set_join, echo=TRUE}
test_set <- temp %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")
```

Add rows removed from testing set back to training set

```{r train_set_edit, echo=TRUE}
removed <- anti_join(temp, test_set)
train_set <- rbind(train_set, removed)
```


## Building The Recommendation Model

I will use different models to compare their RMSE and decide which one is the best.

### Just the average model

The first model is the simplest or using just the average of all ratings.

I will calculate the average of all ratings in the training set.

```{r rat_avg, echo=TRUE}
mu <- mean(train_set$rating)
mu
```

Next is to calculate the first RMSE. To do that I will use all ratings in the test_set as predictions.

```{r rmse_1, echo=TRUE}
rmse_1 <- RMSE(test_set$rating, mu)
```

I will use a table to compare the RMSE results from different methods used.

```{r rmse_table, echo=TRUE}
rmse_table <- data_frame(method = "Just the average", RMSE = rmse_1)
rmse_table
```

### Movie effect model

Since different movies are rated differently, we need to calculate b_i (bias) which is the average ranking of each movie.

```{r movies_avgs, echo=TRUE}
movie_avgs <- train_set %>% group_by(movieId) %>% summarize(b_i = mean(rating - mu))
```

Now I will calculate the second RMSE to see if the predictions improve.

```{r rmse_2, echo=TRUE}
predicted_ratings <- mu + test_set %>% left_join(movie_avgs, by= 'movieId') %>% .$b_i
rmse_2 <- RMSE(predicted_ratings, test_set$rating)
```

I will add the second RMSE to the table to compare it with the first one.

```{r rmse_table_2, echo=TRUE}
rmse_table <- bind_rows(rmse_table, data_frame(method = "Movie effect model", RMSE = rmse_2))
rmse_table
```

The RMSE of the second model is a little bit less than the first one but we still need to find a better model.

### Movie and User Effects Model

Similar to what we did with the movies, I will calculate the average rating for each user and add it to the previous model.

```{r users_avgs, echo=TRUE}
user_avgs <- test_set %>% left_join(movie_avgs, by='movieId') %>% group_by(userId) %>% summarize(b_u = mean(rating - mu - b_i))
```

Now I will calculate the third RMSE to see the results.

```{r rmse_3, echo=TRUE}
predicted_ratings <- test_set %>% left_join(movie_avgs, by='movieId') %>% left_join(user_avgs, by='userId') %>% mutate(pred = mu + b_i + b_u) %>% .$pred
rmse_3 <- RMSE(predicted_ratings, test_set$rating)
```

I will add the third RMSE to the table.

```{r rmse_table_3, echo=TRUE}
rmse_table <- bind_rows(rmse_table, data_frame(method = "Movie + User Effects Model", RMSE = rmse_3))
rmse_table
```

## Evaluation of models

Looking at the results of RMSE in the table we can see that using the Movie and User Effect Model can generate more accurate results. 
The final step is to  fine-tune the predicted ratings so that the minimum and maximum ratings are equal to those in the training set.

```{r tune, echo=TRUE}
predicted_ratings[which(predicted_ratings<1)] <- min(train_set$rating) 
predicted_ratings[which(predicted_ratings>5)] <- max(train_set$rating)
```

## Conclusion

Building a recommendation system for movies requires the consideration of different variabilities such as users, movies, genres, etc. For this project, I decided to use the movie and user effect model as it takes into account the differences between movies and users. This has resulted in an RMSE of around 0.82. However, there are other models that can be used to further improve the accuracy of our recommendation system and we can always test these models with larger set of data for different products.
